package com.viettel.datalake.test


import com.viettel.bi.spark.ext.api.SparkCommand
import com.viettel.datalake.config.GroupIdConfig
import org.apache.spark.sql.SparkSession

import scala.collection.mutable

object main {
//  private var spark: SparkSession = null

//  override def exec(sparkSession: SparkSession, args: Array[String], um: mutable.HashMap[String, Object]): Unit = {
//    val path = "hdfs://10.254.207.62/work_zone/vtmedia/report/unitel"
//    sparkSession.read.format("csv").option("inferSchema", true).option("delimiter", "|").load(path).show()
//  }

//  def main(args: Array[String]): Unit = {
//    val path = "hdfs://10.254.207.62/work_zone/vtmedia/report/unitel"
//    spark.read.format("csv").option("inferSchema", true).option("delimiter", "|").load(path).show()
//  }
}
